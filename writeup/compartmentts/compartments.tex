\documentclass{article}

\usepackage{geometry}
\usepackage{xcolor, colortbl}
\usepackage[most]{tcolorbox}
\usepackage{amsmath, amssymb, stmaryrd}
\usepackage{subcaption}

\begin{document}

\input{macros.tex}
\input{tagrules.tex}

\begin{abstract}

  C code can be challenging to secure due to the prevalence of undefined behavior (UB),
  especially UB related to memory. Using an enforcement system like Tagged C, it is
  straightforward to enforce a memory safety security policy that eliminates all memory
  UB, and this is desirable as they can be major vulnerabilities. But some UB may
  also be supported by common compilers and used by programmers in the wild---the
  ``defacto standard''---and fully protecting all memory objects is expensive.
  The solution: compartmentalization.

  We present a compartmentalization policy that allows some compartments to treat
  memory concretely, enabling the full array of low-level pointer-manipulating idioms
  internally while isolating any errors that arise from such idioms inside the compartment. 
  We prove that under this policy, standard-compliant compartments are protected from
  other compartments that they link with. Conversely, we conjecture that even compartments
  containing memory UB are protect, albeit in a more limited sense, and we
  give a formalization of the nature of this protection.
  
\end{abstract}

\section{Introduction}

\subsection{Why Memory Safety?}

\subsection{Why Not Memory Safety?}

\paragraph{Low-level Idioms}

The first reason not to enforce full memory safety is that code found in the wild may
be memory unsafe in ways that are harmless or even intentional. These ``low-level idioms''
exploit the underlying structure of pointers as integers. In particular, we are interested
in those idioms that create a new pointer to an existing object, either from scratch
(pointer-forging) or by performing arithmetic on a pointer to a different object. Errors
involving these idioms can very easily result in loads and stores to and from the wrong
object, creating serious vulnerabilities. And these idioms are used in practice: for example,
the Linux kernel's per-CPU-variable library maintains a table of offsets that are added to a
base pointer to find one of several separately-allocated objects in memory.

\begin{verbatim}
#define per_cpu_ptr(ptr, cpu) ({ RELOC_HIDE(ptr, __per_cpu_offset[cpu]); })
// RELOC_HIDE computes ptr + offset while hiding from the compiler
\end{verbatim}

It is also common for low-level code to directly access pre-defined addresses that play
some specialized role, such as interfacing with an external piece of hardware.
[TODO: example]

In each of these scenarios, a full memory-safety policy will fail on a normal (safe)
execution! So, we need a policy that can be permissive enough to allow low-level idioms,
but which mitigates their risks by constraining the relevant code to isolated, untrusted compartments.

\paragraph{Performance}

The second reason not to enforce full memory safety is that doing so is likely to be expensive.
The details vary depending on the hardware, but in practice Tagged C policies will likely be
limited to a finite number of ``live'' tags at any given time. In memory-safety policies,
this will be correlated to the number of live objects at any given time, but by relaxing the
policies, we can reduce it. Our smallest policy uses a number of tags that is linear in
the number of live objects that are shared across compartment boundaries.

\subsection{Tagged C and Concrete C}

Here we give a brief overview of Tagged C, discuss its baseline protections, and confirm that
in the absence of other policies it can support all of the low-level idioms discussed above.
This is a good place to plug Concrete C as an independent concept that is useful.

\subsection{Contributions}

Our contributions are:

\begin{itemize}
\item A compartmentalization policy that separates a program into mutually distrustful
  components, which may be ``strict'' (memory safety is enforced internally) or ``lax''
  (permitted to treat memory fully concretely).
\item A pen-and-paper proof that the compartmentalized system preserves the security of a
  safe component from an unsafe one, formalized as a robust safety preservation property.
\item A novel security property, [TODO: give it a name] characterizing the protection offered
  to an unsafe component, formalized in terms of a simplified version of Tagged C. We conjecture
  that our compartmentalization policy enforces [NAME] as well.
\end{itemize}

\section{Compartments by Example}

In Figure \ref{fig:basic}, the function {\tt f} is assumed to always return 0,
because {\tt x[0]} is assigned 0 and not updated before its value is returned. This assumption
is dependent on the system being memory safe---in the absence of memory safety, {\tt g} might
overwrite {\tt x[0]}. The fact that {\tt g} will not overwrite {\tt x} follows from a set of
principles that we might term ``capability reasoning''---working backwards from the fact
that every permitted load or store to an object must be made through pointer that traces
its provenance to that object's initial allocation, we can rule out memory accesses by
proving that no pointer of the relevant provenance is accessible to a given piece of code.

\begin{figure}
  \begin{subfigure}{0.5\textwidth}
\begin{verbatim}
int f() {
  int *x = malloc(sizeof(int)*8);
  int *y = malloc(sizeof(int)*8);

  for (int i = 0; i<8; ++i) {
    x[i] = 0;
    y[i] = 0;
  }

  g();
  return x[0]; // always returns 0
}
\end{verbatim}
  \end{subfigure}
  
\caption{}
\label{fig:basic}
\end{figure}

But, there are several reasons why we might not want to enforce full memory safety.
For one thing, it's expensive. For another, the definition of {\tt g} might
contains some undefined memory behavior that doesn't directly impact {\tt x}.

Instead of memory safety, we can apply a compartmentalization policy that separates {\tt g}
from {\tt f}, so that they cannot both access the same memory locations. This essentially
merges {\tt x} and {\tt y}, from a protection perspective: they can both be accessed by {\tt f},
even if {\tt f} should contain some undefined behavior, and only by {\tt f}.
Therefore, as before, {\tt x[0]} will not change during the call.
In performance terms, we halve the number of tags necessary to protect the two arrays.

\begin{figure}
  \begin{subfigure}{0.5\textwidth}
\begin{verbatim}
int f() {
  int *x = malloc(sizeof(int)*8);
  int *y = malloc(sizeof(int)*8);
  int *z = malloc(sizeof(int)*8);

  for (int i = 0; i<8; ++i) {
    x[i] = 0;
    y[i] = 0;
    z[i] = i;
  }

  g(z);
  return x[0]; // always returns 0
}
\end{verbatim}
  \end{subfigure}
  
\caption{}
\label{fig:share}
\end{figure}

But, now consider the version of {\tt f} in Figure \ref{fig:share}. It's now passing a pointer,
{\tt z}, to {\tt g}. Our strict separation no longer works! This program will still run, and
{\tt x} will still be protected, under a full memory safety policy. But under our compartmentalization
policy, if {\tt g} attempts to read or write {\tt z}, execution will failstop.

We need a hybrid model that allows some objects to be shared, while still allowing us to merge
{\tt x} and {\tt y} for efficiency. Escape analysis can determine which objects need to be shared,
by allocation site; we assume that the code is rewritten so that calls to {\tt malloc} that should
be shared are replaced by a special {\tt malloc\_share} call, which behaves identically except
in terms of how the policy treats it.

Now, the question that we have to answer is: how fine-grained to we need our protection of the
shared objects to be? We have a few different options.
\begin{itemize}
\item All shared objects are grouped together
\item All objects are grouped according to which compartment(s) they are shared with
\item Objects are grouped by allocation-site
\item Each object is kept separate, with no grouping at all
\end{itemize}

Our guiding principle here is that we want to preserve all of the properties of
a memory safe system, so keeping each object separate will definitely work. It would be
nice to be able to compress them further, but it turns out that each kind of grouping will
cost us something.

\begin{figure}
  \begin{subfigure}[t]{0.49\textwidth}
\begin{verbatim}
A >> int f() {
  int* x = malloc_share(sizeof(int));
  int* y = malloc_share(sizeof(int));
  g(x);
  x[0] = 0;
  h(y);
  return x[0];
}

B >> void g(int*);

C >> void h(int*);
\end{verbatim}
    \caption{}
    \label{subfig:allshare}
  \end{subfigure}
  \begin{subfigure}[t]{0.49\textwidth}
\begin{verbatim}
A >> int f() {
  int* x;
  for (int i = 0; i < 100; i++) {
    x = malloc_share(sizeof(int));
    if (i % 2) {
      g(x);
    } else {
      h(x);
    }
  }
  return x[0];
}
\end{verbatim}
    \caption{}
    \label{subfig:escapeshare}
  \end{subfigure}

  \caption{}
  \label{fig:groupings}
\end{figure}

First, in Figure \ref{subfig:allshare}, if {\tt g} and {\tt h} are
in separate compartments that do not call one another, we should be able to rely on
{\tt x[0]} staying constant during the call to {\tt h}. But if we group all shared objects
together, then sharing {\tt y} with compartment {\tt B} implicitly means sharing
{\tt x} as well.

We might consider grouping together objects based on which compartment(s) they're going to
be shared with. One could imagine approximating the set of compartments that the objects
from a given allocation site might escape to, and grouping together all objects that escape
to the exactly the same set of compartments. This is unworkable; it is simple to construct
an example like Figure \ref{subfig:escapeshare}, where objects' sharing behavior is finer-grained
than their allocation-site. There are also temporal factors to consider: if a pointer is shared
to {\tt B} early in its lifetime, and {\tt C} much later, can we rely on its safety from
{\tt C} in the interim? This last concern seems to be the final nail in the coffin of any
meaningful groupings. So, we must tag every shared object uniquely unless we're willing
to give up capability-reasoning for all shared objects.

If we are willing to give up capability reasoning for all shared objects, then it isn't clear
that we gain anything from grouping them more finely. This might not be so bad; in our original
motivating example, we were concerned with {\tt x} being protected, and as {\tt x} does not escape
at all, its allocation site will not be marked shared. This is a narrower form of reasoning, one
that we might call ``escape-local'' reasoning.

\section{Compartmentalization Without Sharing}

As a first step toward our ultimate goal, let's think about a simpler kind of protection:
separating the world into strict and lax compartments that do not share memory.

\subsection{Policy In Detail}

A Tagged C policy consists of a tag type \(\tau\), a {\it policy state} type \(\sigma\),
and instantiations of a set of {\it tag rules}, each of which parameterizes the behavior
of key {\it control points} in the semantics. Tag rules are written in a procedural style,
assigning tags to their outputs by name. The state \(s : \sigma\) can always be accessed
and assigned to.
\sna{This is going to be a real pain to explain so that it can be followed without
  reading the last paper.}

\paragraph{Relevant Policy Rules}

Without further ado, let's define our policy. Tags consist of compartment identifiers
\(\mathbf{comp}(C)\) and per-compartment allocation colors \(\mathbf{clr}(C,a)\), where
\(a\) is a natural number. The policy state is a counter that tracks the next allocation color.
\[\tau ::= \mathbf{comp}(C) | \mathbf{clr}(C,a) | \emptyset \]
\[\sigma := \mathbb{N} \]
We assume a mapping \(owner\) from function and global identifiers to compartments,
and initialize tags such that the function pointer tag for each function \(f\) is \(owner(f)\).
The trusted compartment set \(\mathit{strict} ~ C\) contains all of the compartments that
we wish to enforce memory safety within. We start by keeping track of which compartment we're in.

\begin{minipage}{0.49\textwidth}
  \calltruleblock{\(\PCT['] := pt\)}
\end{minipage}
\begin{minipage}{0.49\textwidth}
  \rettruleblock{\(\PCT['] := \PCT[_{CLR}]\)}
\end{minipage}

The memory locations of global variables are tagged with the compartment that owns them.
Dynamic memory is more complicated. We first check whether the active compartment is strict.
If it is lax, the allocated memory is tagged with the compartment identity only. But if it is
strict, both the pointer and the memory location are tagged with the owning compartment and
a fresh allocation color. Once we have a color attached to a pointer, it is propagated along
with the pointer, including through any arithmetic operations provided that the other operand
is not tagged as a pointer.

\hspace{-5em}
\begin{minipage}{0.35\textwidth}
  \localtruleblock{
    let \(\mathbf{comp}(C)\) := \(\PCT\) in \\
    \(\vt['] := \emptyset;\) \\
    if \(\mathit{safe} ~ C\) \\
    then \begin{tabular}[t]{l}
      \(\pt['] := \mathbf{clr}(C,s);\) \\
      \(\lt['] := \mathbf{clr}(C,s);\) \\
      \(s := s+1\)
    \end{tabular} \\
    else \begin{tabular}[t]{l}
      \(\pt['] := \mathbf{comp}(C);\) \\
      \(\lt['] := \mathbf{comp}(C);\) \\
    \end{tabular} \\
  }
\end{minipage}
\begin{minipage}{0.35\textwidth}
  \malloctruleblock{
    let \(\mathbf{comp}(C)\) := \(\PCT\) in \\
    \(\vt['] := \emptyset;\) \\
    if \(\mathit{safe} ~ C\) \\
    then \begin{tabular}[t]{l}
      \(\pt['] := \mathbf{clr}(C,s);\) \\
      \(\lt['] := \mathbf{clr}(C,s);\) \\
      \(s := s+1\)
    \end{tabular} \\
    else \begin{tabular}[t]{l}
      \(\pt['] := \mathbf{comp}(C);\) \\
      \(\lt['] := \mathbf{comp}(C);\) \\
    \end{tabular} \\
  }
\end{minipage}
\begin{minipage}{0.29\textwidth}
  \globaltruleblock{\(\vt['] := \emptyset;\) \\ \(\lt['] := owner(\mathtt{x})\)}

  \binoptruleblock{
    \caseofthree{\(\vt[_1], \vt[_2]\)}
                {\(\mathbf{clr}(C,a),\emptyset\) \\ \(\emptyset, \mathbf{clr}(C,a)\)}{\(\mathbf{clr}(C,a)\)}
                {\(\emptyset,\emptyset\)}{\(\emptyset\)}
                {\(\underline{~~}, \underline{~~}\)}{\(\fail\)}
  }
\end{minipage}

Like allocations, loads and stores have different behavior depending on whether or not the active
compartment is strict or lax. In a lax compartment, it merely compares the PC tag to the location
tag of the target address. In a strict compartment, it also checks that the pointer color matches
that of the target address.

\hspace{-5em}
\begin{minipage}{0.55\textwidth}
  \loadtruleblock{
    let \(\mathbf{comp}(C)\) := \(\PCT\) in \\
    if \(\mathit{strict} ~ C\) \\
    then \(\mathbf{assert} ~ \lt = \mathbf{comp}(C)\) \\
    \(\vt['] := \vt\) \\
    else \(\mathbf{assert} ~ \exists a . \pt = \mathbf{clr}(C,a) \land \lt = \mathbf{clr}(C,a)\) \\
    \(\vt['] := \vt\) \\
  }
\end{minipage}
\begin{minipage}{0.44\textwidth}
  \storetruleblock{
    let \(\mathbf{comp}(C)\) := \(\PCT\) in \\
    if \(\mathit{strict} ~ C\) \\
    then \(\mathbf{assert} ~ \lt = \mathbf{comp}(C)\) \\
    \(\PCT['] := \PCT; \vt['] := \vt; \lt['] := \lt\) \\
    else \(\mathbf{assert} ~ \exists a . \pt = \mathbf{clr}(C,a) \land \lt = \mathbf{clr}(C,a)\) \\
    \(\PCT['] := \PCT; \vt['] := \vt; \lt['] := \lt\) \\
  }
\end{minipage}

Note that this policy allows pointers to be passed between compartments, but they can only
be accessed by the compartment that allocated them. This is a simplification to introduce
the structure of the safety properties, and we will relax it later.

When we deallocate any object, we clear its location tags, so old floating pointers
can no longer read or write to it.

\subsection{Proving Protection}

%\paragraph{Setting and Attacker Model}

%Our proofs are phrased in terms of a program with two compartments: a strict compartment
%that is protected, and a lax one that may be compromised. The lax
%component may contain arbitrary C code, including code with undefined behavior, representing
%the worst-case scenario for a compromised component.

%We do not need to define these conditions formally, because they are implicitly enforced by
%the memory safety policy. Instead, we take memory safety as a reference point and define safe
%compartmentalization in terms of preserving all of these implicit properties.

\paragraph{Concrete C Semantics}

A program's behavior is determined by its Tagged C semantics, which is in turn derived from the
Concrete C semantics. Let's first ignore tags and describe how the Concrete C semantics behaves
with memory.

Concrete C promises to fulfill a set of memory axioms, but the means by which it does so
is nondeterministic. So, for example, a call to malloc may failstop (indicating that the system
it out of memory) or it may return a pointer, with the guarantee that the block beginning at
that pointer does not overlap with any allocated block. Subject to that guarantee, the block
might be anywhere in the address space. This is one source of nondeterminism.

The behavior of loads and stores differs depending on whether they are accessing allocated memory.
A load or store that accesses allocated memory guarantees the usual set of properties of
memory: a load produces the last stored value, etc. A load or store outside of allocated memory
has fewer guarantees. It may failstop, for instance because the accessed address is reserved for
the compiler, or it may proceed, in which case the normal properties of memory apply only up to
a call or return, when the compiler is free to scramble unallocated memory however it sees fit.

%This means that we might consider a few different classes of programs:
%\begin{enumerate}
%\item Programs that always have the same behavior, modulo out-of-memory stops
%\item Programs that always have the same behavior but may failstop (non-OOM)
%\item Programs whose behavior is fully non-deterministic
%\end{enumerate}

%Notably, valid C programs are always in category 1. So are valid PVI and PNVI programs.
%Category 2 consists of programs that access unallocated memory, but only in a consistent way,
%such as a program that loads a value but doesn't use it. Category 3 includes all instances in which
%an object could be written to without a valid pointer, and read and the value used, unless
%the same object/offset is accessed in every memory layout. Since that level of consistency
%is generally only possible using pointer arithmetic from a valid pointer in the first place,
%category 3 is where we find instances of pointer-forging and various probabilistic attacks.

\paragraph{Isolated Semantics}

Our specification for the no-sharing case is derived from a machine in which memory is
isolated by construction. Where previously we had a single flat memory, we now have a
map from compartments to flat memories. The state tracks at any given time which compartment
is active.

\[M \in \mathcal{M} : \mathit{comp} \rightarrow \mathit{mem}\]

Regular state now extended with a compartment id and a memory map:

\[\mathcal{S}(C, M, le, te \mid s \gg k \tagat \PCT)\]

We adjust all of the step relation rules appropriately.
\sna{It's unclear to me whether this semantics should have tags. Probably not, in which
  case it really does look a lot like Concrete C.}

We add one additional axiom, the {\it compatible\_alloc} axiom, which states that
at no point during execution is an address allocated in more than one compartment.
\sna{Without this, we will have traces that can appear in the source but not the target.
  That's a problem if some interesting behavior only occurs in those traces (seems unlikely,
  but maybe possible when we've used a lot of memory.)}

\paragraph{Events and Traces}

Compartments interact via calls and returns, and via loads and stores.

Formally, an event value is a value with an optional provenance. An event is a call, return,
alloc, free, load, or store. An alloc records the range of addresses that are allocated and
gives them a unique provenance. A load or a store always records the provenance of the pointer
being accessed (which means that it needs to be a valid pointer so as to have a provenance);
a load or store with no provenance is not visible in the trace. It also gives the range of
addresses affected.

\[ev ::= v | (\phi, v)\]
\[\begin{split}
e ::= & C \gg \mathit{call} ~ f ~ \overline{ev} \\
| & C \gg \mathit{return} ~ ev \\
| & C \gg \mathit{alloc} ~ a_0 \dots a_n \\
| & C \gg \mathit{free} ~ a_0 \dots a_n \\
| & C \gg \mathit{load} ~ a_0 \dots a_n ~ ev \\
| & C \gg \mathit{store} ~ a_0 \dots a_n ~ ev \\
\end{split}\]

A trace is a (possibly infinite) sequence of events.

Let \(A\) and \(B\) be components such that linking them produces a complete program.
We write the linked program \(A[B]\). Now we need to capture its traces. Execution is
deterministic given a certain compiler/allocation strategy. We range over these with
the metavariable \(\alpha\), and write that a particular combination of program \(A[B]\),
\(\alpha\), and tag policy \(\rho\) produces a trace \(t\) as
\(\alpha \vdash A[B] \rightsquigarrow_{\mathit{tag(\rho)}} t\). To write the same given
the multi-concrete model, we write \(\alpha \vdash A[B] \rightsquigarrow_{\mathit{mc}} t\).
Producing a trace is defined inductively
in terms of the step function such that if \(\alpha \vdash A[B] \rightsquigarrow_X t\),
then \(\alpha \vdash A[B] \rightsquigarrow_X s\) for any \(s\) that prefixes \(t\).

We frequently want to talk about all possible traces of a program under a given policy
or the multi-concrete model regardless of the memory layout. In this case we define the
trace set \(\llbracket A[B] \rrbracket_X\) where \(X\) is \(\mathit{mc}\) or \(\mathit{tag}(\rho)\).

\[\llbracket A[B] \rrbracket_X \triangleq \bigcup_{\alpha}
\{ t \mid \alpha \vdash A[B] \rightsquigarrow_X t \}\]

\paragraph{Properties and the Big Property}

A property \(\pi\) is a set of traces, members of which are said to satisfy \(\pi\).

A property \(\pi\) is {\em robustly satisfied (def 1)} by a compartment \(A\) under context \(X\)
if, for all \(B\), \(\llbracket A[B] \rrbracket_X \subseteq \pi\).

A policy \(\rho\) enjoys {\em robust property satisfaction (def 1)} with respect to \(ms\)
if, for all \(A\) and all \(\pi\) robustly satisfied by \(A\) under \(ms\),
\(A\) robustly satisfies \(\pi\) under \(tag(\rho)\).

By the contrapositive, this is equivalent to: for all \(A\), \(B\), and \(t\) such that
\(t \in \llbracket A[B] \rrbracket_{tag(\rho)}\),

\paragraph{Trace Examples}

\begin{figure}

\begin{verbatim}
A >> f() {
  int* x = malloc(sizeof(int));
  
  return (int) x;
}
\end{verbatim}

\[\llbracket A[B] \rrbracket =
\{\dots \mathit{call} ~ f ~ [] \cdot \mathit{return} ~ 8*i \ldots \mid 0 \leq i \leq 2^{61}\}\]

\begin{verbatim}
A >> f() {
  int* x = malloc(sizeof(int));
  int* y = malloc(sizeof(int));
  
  return (int) x + (int) y);
}
\end{verbatim}

\[\llbracket A[B] \rrbracket =
\{\dots \mathit{call} ~ f ~ [] \cdot \mathit{return} ~ 8*(i+j) \ldots \mid 0 \leq i \leq 2^{61}, 0 \leq i \leq j, i \not = j\}\]

\begin{verbatim}
A >> f() {
  int* x = malloc(sizeof(int));
  int* y = malloc(sizeof(int));

  if ((int) x < (int) y && (int) x > (int) y) {
    return 1;
  } else {
    return 0;
  }
}
\end{verbatim}

\[\llbracket A[B] \rrbracket = \{\dots \mathit{call} ~ f ~ [] \cdot \mathit{return} ~ 0 \ldots\}\]

\caption{Addresses not in Traces}
\label{fig:traddr}
\end{figure}




Let's look at an example of a program and the trace it produces. In Figure \ref{fig:trexample},
we see multiple kinds of undefined behavior, as {\tt f} has internal {\tt UB} and {\tt g} has
external. We give a full execution trace of the program (one of many, selecting arbitrary addresses
for allocations), marking where it will be truncated by a failstop under each policy in red.

\begin{figure}
  \begin{subfigure}{\textwidth}
    \begin{minipage}[t]{0.5\textwidth}
\begin{verbatim}
A >> int f() {
2      int* x = malloc(sizeof(int)*4);
3      int* y = malloc(sizeof(int)*4);
4      int off = y - x;
5      x[0] = 0;
6      x[off] = 42;
7      g(x,0);
8      g(x,off);
9
10     return y[0];
11   }
\end{verbatim}
    \end{minipage}
    \begin{minipage}[t]{0.4\textwidth}
\begin{verbatim}
B >> int g(int* p, int i) {
12     p[i] = 5;
13   }

B >> int main() {
16     return f();
17   }
\end{verbatim}
    \end{minipage}
  \end{subfigure}
  \begin{subfigure}{\textwidth}
    \[\begin{split}
    A[B] \rightsquigarrow & \mathit{call} ~ f ~ [] \cdot
    \mathit{alloc} ~ \phi_0 ~ \mathtt{0xAB00} \dots \mathtt{0xAB0F} \cdot \\
    & \mathit{alloc} ~ \phi_1 ~ \mathtt{0xAB20} \dots \mathtt{0xAB2F} \cdot
    \mathit{store} ~ \phi_0 ~ \mathtt{0xAB20} \dots \mathtt{0xAB23} ~ 42 ~
           {\color{red} \mid \textnormal{\sc ms}} \\
    & \mathit{call} ~ g ~ [(\phi_0, \mathtt{0xAB00}); 0] \cdot
    \mathit{load} ~ \phi_0 ~ \mathtt{0xAB00} \dots \mathtt{0xAB03} ~ 0 ~
           {\color{red} \mid \textnormal{\sc noshare}} \\
    & \mathit{call} ~ g ~ [(\phi_0, \mathtt{0xAB00}); 32] \cdot
    \mathit{load} ~ \phi_0 ~ \mathtt{0xAB20} \dots \mathtt{0xAB23} ~ 42 ~
           {\color{red} \mid \textnormal{\sc share}} \\
    & \mathit{return} \cdot \mathit{return} ~ 42 \\
    \end{split}\]
  \end{subfigure}
  
  \caption{Example With Cross-compartment Sharing and Pointer Arithmetic}
  \label{fig:trexample}
\end{figure}

As we truncate the trace, we eliminate interactions between compartments. 
[TODO: say something intelligent here about what kinds of interactions.]
Quantifying over all programs, some of our policies eliminate whole classes of interactions
between compartments. Full memory safety is the most restrictive, and as it corresponds
to the C standard, it forms the basis of our overall security property: for a particular
interesting class of inter-compartment interactions, our compartmentalization policies should
not be any more permissive than {\sc ms}.

%Informally, we can get a sense of certain kinds of interactions that we just eliminated.
%[Example] very clearly violated the array abstraction \sna{Is that the right term?} by
%causing the code to read a different value from [address] than it wrote; with memory safety
%we the trace is truncated before that violation. In [example], [pointer] is never passed outside
%[compartment], yet it is written to by [compartment]; likewise, memory safety prevents this.

\paragraph{Robust Safety Preservation}

This brings us to the definition of {\em robust safety preservation}. First, we define the
class of {\em safety properties} as those properties \(\pi\) which can always be falsified by
a finite prefix of a trace. Now, for any compartment ``under focus'', \(C\), consider the set
of safety properties {\em robustly satisfied} by \(C\) under some policy \(\rho\):

\[\overline{\pi}(C)_\rho \triangleq \{ \pi \mid \forall A ~ t .
C[A] \rightsquigarrow_\rho t \rightarrow t \in \pi \}\]

For any pair of policies \(\rho\) and \(\rho'\), we say that \(\rho'\) enjoys robust
safety preservation with respect to \(\rho\) if, for all \(C\),
\(\overline{\pi}(C)_\rho \subseteq \overline{\pi}(C)_{\rho'}\).

\subsection{Proof}

\section{Safely Sharing Memory}

Now we extend the policy above to allow sharing memory. The crucial difference is that
safe pointers are no longer tied to particular compartments; instead, we distinguish
between {\it allocation points}---that is, calls to malloc, grouped according to
whether or not the allocated object should be shared between compartments.
So, we add another tag, \(\mathbf{share}\), which is attached to the function pointer
of each call to malloc that is meant to be shared.

\[\tau ::= \mathbf{comp}(C) | \mathbf{clr}(a) | \emptyset | \mathbf{share} \]

For simplicity, we focus exclusively on malloc and disallow sharing of stack pointers;
these are therefore tagged with \(\mathbf{comp}\) for every compartment. The malloc rule
checks the tag on the function pointer being called to determine how to proceed.

\hspace{-5em}
\begin{minipage}{0.35\textwidth}
  \localtruleblock{
    let \(\mathbf{comp}(C)\) := \(\PCT\) in \\
    \(\vt['] := \emptyset;\) \\
    \(\pt['] := \mathbf{comp}(C);\) \\
    \(\lt['] := \mathbf{comp}(C);\) \\
    }
\end{minipage}
\begin{minipage}{0.35\textwidth}
  \malloctruleblock{
    \(\vt['] := \emptyset;\) \\
    if \(\pt = \mathbf{share}\) \\
    then \begin{tabular}[t]{l}
      \(\pt['] := \mathbf{clr}(s);\) \\
      \(\lt['] := \mathbf{clr}(s);\) \\
      \(s := s+1\)
    \end{tabular} \\
    else \begin{tabular}[t]{l}
      \(\pt['] := \PCT;\) \\
      \(\lt['] := \PCT;\) \\
    \end{tabular}
  }
\end{minipage}
\begin{minipage}{0.29\textwidth}
  \binoptruleblock{
    \caseofthree{\(\vt[_1], \vt[_2]\)}
                {\(\mathbf{clr}(a),\emptyset\) \\ \(\emptyset, \mathbf{clr}(a)\)}{\(\mathbf{clr}(a)\)}
                {\(\emptyset,\emptyset\)}{\(\emptyset\)}
                {\(\underline{~~}, \underline{~~}\)}{\(\fail\)}
  }
\end{minipage}

Safe pointer tags are propagated similarly to before, as are loads and stores.

\begin{minipage}{0.45\textwidth}
  \loadtruleblock{
    if \(\lt = \mathbf{comp}(\underline{~})\) \\
    then \(\mathbf{assert} ~ \PCT = \lt\) \\
    \(\vt['] := \vt\) \\
    else \(\mathbf{assert} ~ \pt = \lt\) \\
    \(\vt['] := \vt\) \\
  }
\end{minipage}
\begin{minipage}{0.45\textwidth}
  \storetruleblock{
    if \(\lt = \mathbf{comp}(\underline{~})\) \\
    then \(\mathbf{assert} ~ \PCT = \lt\) \\
    \(\PCT['] := \PCT; \vt['] := \vt; \lt['] := \lt\) \\
    else \(\mathbf{assert} ~ \pt = \lt\) \\
    \(\PCT['] := \PCT; \vt['] := \vt; \lt['] := \lt\) \\
  }
\end{minipage}

\subsection{Proving Safety with Sharing}

We need to axiomatize the fact that only the lax compartment is allowed to
do memory unsafe things.

\section{Trust While Using Unsafe Idioms}

While we have proven that our compartmentalization policy protects our strict
compartment from lax ones, we conjecture that it can also protect a lax compartment
from an attacker that aims to exploit its non-standard behavior. But what does it mean
for a compartment to be protected when it contains UB? To demonstrate the difficulty,
consider the following example:

\begin{verbatim}
C >> f() {
  int x[10];
  x[10] = 42;
  return 5;
}
\end{verbatim}

Since {\tt f} writes out of bounds, its behavior is undefined, and under a full memory safety
policy it will always failstop---which in turn means that it will vacuously satisfy all safety
properties robustly. Under our compartmentalization policy, the write to {\tt x[10]} will either
be successful (but unstable) or it will failstop. If it doesn't failstop, {\tt f} returns 5,
which means that there are a large number of safety properties no satisfied. Clearly,
we cannot expect our policy to preserve arbitrary safety properties that are satisfied in
a memory safe setting.

Instead, we define a new partial memory model in which each compartment has its own private
(concrete) address space. The model is axiomatized such that, in each private address space,
in-bounds loads and stores behave as expected, while out-of-bounds accesses are unstable and
may failstop. This memory model forms the specification from which we derive a robust
safety preservation property.

\sna{After some consideration, I've come to the conclusion that this is the approach
  most likely to work. One con: this means I have to actually define that memory model
  (but I envision it being basically n Concrete C memories stacked on top of one another).}

%\section{Related Work}

%There is a whole bunch of work that deals with similar concepts that we need to
%distinguish ourselves from. This is fundamentally a compartmentalization paper,
%so we need to justify the novelty of our approach to compartments, and since we
%are making claims in the secure compilation space we need to show how we stack up there.

%\subsection{Comparing to Compartmentalization Schemes}

%The key points of comparison with other compartmentalization schemes are in whether they
%support sharing, and more broadly, how they divide up the program.

%\paragraph{Catalin's group and other ``no sharing'' schemes}

%The sharing of memory between compartments can be difficult to implement in many enforcement
%mechanism, and even when it is not, it may make proofs about the system more challenging.
%It is straightforward to implement in Tagged C. How hard it is for proofs remain to be seen.
%\sna{I am strongly opposed to removing sharing, I would rather ditch the proofs if I must.}

%We follow Catalin's group in separating programs into compartments by grouping functions,
%and giving each compartment access to its own data, including everything that it allocates.

%\paragraph{Mandatory Access Control}

%The alternative to grouping functions with their own data is Mandatory Access Control.
%In this setting, functions are ``subjects'' and other data are ``objects.'' A compartmentalization
%scheme comprises a table mapping subjects to the objects that they are allowed to access.
%The downside of this approach is that it can take a lot of effort to assign subjects and objects
%and write the table!

%\subsection{Comparing to Secure Compilation Work}

%We compare ourselves to the secure compilation literature in terms of our properties.
%The paper will have already gone into robust safety preservation, so we need to convince
%ourselves there the other relevant properties aren't suitable.

%\paragraph{Full Abstraction}

%For a long time, fully abstract compilation (preservation of observational equivalence) was
%the go-to property for secure compilation. The secure compilation world has moved away from
%it largely because it tends to be too strong. Observational equivalence being a hyperproperty,
%it is too strong for enforcement mechanisms that can only preserve safety properties.
%That means that it doesn't work for us, either.
%\sna{But I should still go into more detail about that.}

%\paragraph{Dynamic Compromise}

%We should compare our attacker model to the Dynamic Compromise of Abate et. al. In their model,
%a compromised component---one that has encountered UB during its run---is dynamically replaced
%by an arbitrary assembly program. This represents a very general view of UB: in the presence of UB,
%a compiler might produce any assembly whatsoever. By contrast, in the world of Tagged C,
%all memory-UB is given a reasonable concrete definition,
%so our model constrains the attacker to that definition. It is a strength of Concrete C that
%we are able to work in this simpler attacker model.

\end{document}
